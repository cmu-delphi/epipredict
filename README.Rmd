---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
options(width = 76)
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

```{r coloration, include=FALSE, echo=FALSE}
base <- "#002676"
primary <- "#941120"
secondary <- "#f9c80e"
tertiary <- "#177245"
fourth_colour <- "#A393BF"
fifth_colour <- "#2e8edd"
colvec <- c(
  base = base, primary = primary, secondary = secondary,
  tertiary = tertiary, fourth_colour = fourth_colour,
  fifth_colour = fifth_colour
)
library(epiprocess)
suppressMessages(library(tidyverse))
theme_update(legend.position = "bottom", legend.title = element_blank())
delphi_pal <- function(n) {
  if (n > 6L) warning("Not enough colors in this palette!")
  unname(colvec)[1:n]
}
scale_fill_delphi <- function(..., aesthetics = "fill") {
  discrete_scale(aesthetics = aesthetics, palette = delphi_pal, ...)
}
scale_color_delphi <- function(..., aesthetics = "color") {
  discrete_scale(aesthetics = aesthetics, palette = delphi_pal, ...)
}
scale_colour_delphi <- scale_color_delphi
```

# Epipredict

<!-- badges: start -->
[![R-CMD-check](https://github.com/cmu-delphi/epipredict/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/cmu-delphi/epipredict/actions/workflows/R-CMD-check.yaml)
<!-- badges: end -->

**Note:** This package is currently in development and may not work as expected. Please file bug reports as issues in this repo, and we will do our best to address them quickly.

## Installation

To install (unless you're making changes to the package, use the stable version):

```r
# Stable version
pak::pkg_install("cmu-delphi/epipredict@main")

# Dev version
pak::pkg_install("cmu-delphi/epipredict@dev")
```

## Documentation

You can view documentation for the `main` branch at <https://cmu-delphi.github.io/epipredict>.

## Goals for `epipredict`

<details>
<summary> Creating the dataset using `{epidatr}` and `{epiprocess}` </summary>
This dataset can be found in the package as <TODO DOESN'T EXIST>; we demonstrate some of the typically ubiquitous cleaning operations needed to be able to forecast.
First we pull both jhu-csse cases and deaths from [`{epidatr}`](https://cmu-delphi.github.io/epidatr/) package:
```{r case_death}
cases <- pub_covidcast(
  source = "jhu-csse",
  signals = "confirmed_incidence_prop",
  time_type = "day",
  geo_type = "state",
  time_values = epirange(20200601, 20220101),
  geo_values = "*"
) |>
  select(geo_value, time_value, case_rate = value)

deaths <- pub_covidcast(
  source = "jhu-csse",
  signals = "deaths_incidence_prop",
  time_type = "day",
  geo_type = "state",
  time_values = epirange(20200601, 20220101),
  geo_values = "*"
) |>
  select(geo_value, time_value, death_rate = value)
cases_deaths <-
  full_join(cases, deaths, by = c("time_value", "geo_value")) |>
  as_epi_df(as_of = as.Date("2022-01-01"))
plot_locations <- c("ca", "ma", "ny", "tx")
# plotting the data as it was downloaded
cases_deaths |>
  filter(geo_value %in% plot_locations) |>
  pivot_longer(cols = c("case_rate", "death_rate"), names_to = "source") |>
  ggplot(aes(x = time_value, y = value)) +
  geom_line() +
  facet_grid(source ~ geo_value, scale = "free") +
  scale_x_date(date_breaks = "3 months", date_labels = "%Y %b") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
As with basically any dataset, there is some cleaning that we will need to do to make it actually usable; we'll use some utilities from [`{epiprocess}`](https://cmu-delphi.github.io/epiprocess/) for this.
First, to eliminate some of the noise coming from daily reporting, we do 7 day averaging over a trailing window[^1]:

[^1]: This makes it so that any given day of the processed timeseries only depends on the previous week, which means that we avoid leaking future values when making a forecast.

```{r smooth}
cases_deaths <-
  cases_deaths |>
  group_by(geo_value) |>
  epi_slide(
    cases_7dav = mean(case_rate, na.rm = TRUE),
    death_rate_7dav = mean(death_rate, na.rm = TRUE),
    .window_size = 7
  ) |>
  ungroup() |>
  mutate(case_rate = NULL, death_rate = NULL) |>
  rename(case_rate = cases_7dav, death_rate = death_rate_7dav)
```

Then trimming outliers, most especially negative values:
```{r outlier}
cases_deaths <-
  cases_deaths |>
  group_by(geo_value) |>
  mutate(
    outlr_death_rate = detect_outlr_rm(time_value, death_rate, detect_negatives = TRUE),
    outlr_case_rate = detect_outlr_rm(time_value, case_rate, detect_negatives = TRUE)
  ) |>
  unnest(cols = starts_with("outlr"), names_sep = "_") |>
  ungroup() |>
  mutate(
    death_rate = outlr_death_rate_replacement,
    case_rate = outlr_case_rate_replacement
  ) |>
  select(geo_value, time_value, case_rate, death_rate)
cases_deaths
```
</details>

After having downloaded and cleaned the data in `cases_deaths`, we plot a subset
of the states, noting the actual forecast date:

<details>
<summary> Plot </summary>
```{r plot_locs}
forecast_date_label <-
  tibble(
    geo_value = rep(plot_locations, 2),
    source = c(rep("case_rate", 4), rep("death_rate", 4)),
    dates = rep(forecast_date - 7 * 2, 2 * length(plot_locations)),
    heights = c(rep(150, 4), rep(1.0, 4))
  )
processed_data_plot <-
  cases_deaths |>
  filter(geo_value %in% plot_locations) |>
  pivot_longer(cols = c("case_rate", "death_rate"), names_to = "source") |>
  ggplot(aes(x = time_value, y = value)) +
  geom_line() +
  facet_grid(source ~ geo_value, scale = "free") +
  geom_vline(aes(xintercept = forecast_date)) +
  geom_text(
    data = forecast_date_label, aes(x = dates, label = "forecast\ndate", y = heights), size = 3, hjust = "right"
  ) +
  scale_x_date(date_breaks = "3 months", date_labels = "%Y %b") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```
</details>
```{r show-processed-data, warning=FALSE, echo=FALSE}
processed_data_plot
```

To make a forecast, we will use a "canned" simple auto-regressive forecaster to predict the death rate four weeks into the future using lagged[^3] deaths and cases

[^3]: lagged by 3 in this context meaning using the value from 3 days ago.

```{r make-forecasts, warning=FALSE}
two_week_ahead <- arx_forecaster(
  covid_case_death_rates,
  outcome = "death_rate",
  predictors = c("case_rate", "death_rate"),
  args_list = arx_args_list(
    lags = list(c(0, 1, 2, 3, 7, 14), c(0, 7, 14)),
    ahead = 14
  )
)
two_week_ahead
```

In this case, we have used 0-3 days, a week, and two week lags for the case
rate, while using only zero, one and two weekly lags for the death rate (as
predictors).
The result `four_week_ahead` is both a fitted model object which could be used
any time in the future to create different forecasts, as well as a set of
predicted values (and prediction intervals) for each location 28 days after the
forecast date.
Plotting the prediction intervals on our subset above[^2]: 

[^2]: Alternatively, you could call `auto_plot(four_week_ahead)` to get the full collection of forecasts. This is too busy for the space we have for plotting here.

<details>
<summary> Plot </summary>
This is the same kind of plot as `processed_data_plot` above, but with the past data narrowed somewhat
```{r}
narrow_data_plot <-
  cases_deaths |>
  filter(time_value > "2021-04-01") |>
  filter(geo_value %in% plot_locations) |>
  pivot_longer(cols = c("case_rate", "death_rate"), names_to = "source") |>
  ggplot(aes(x = time_value, y = value)) +
  geom_line() +
  facet_grid(source ~ geo_value, scale = "free") +
  geom_vline(aes(xintercept = forecast_date)) +
  geom_text(
    data = forecast_date_label, aes(x = dates, label = "forecast\ndate", y = heights), size = 3, hjust = "right"
  ) +
  scale_x_date(date_breaks = "3 months", date_labels = "%Y %b") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

Putting that together with a plot of the bands, and a plot of the median prediction.
```{r plotting_forecast, warning=FALSE}
epiworkflow <- four_week_ahead$epi_workflow
restricted_predictions <-
  four_week_ahead$predictions |>
  filter(geo_value %in% plot_locations) |>
  rename(time_value = target_date, value = .pred) |>
  mutate(source = "death_rate")
forecast_plot <-
  narrow_data_plot |>
  epipredict:::plot_bands(
    restricted_predictions,
    levels = 0.9,
    fill = primary
  ) +
  geom_point(data = restricted_predictions, aes(y = .data$value), color = secondary)
```

```{r show-single-forecast, warning=FALSE, echo=FALSE}
forecast_plot
```
The yellow dot gives the median prediction, while the red interval gives the 5-95%  inter-quantile range.
For this particular day and these locations, the forecasts are relatively accurate, with the true data being within the 25-75% interval.
A couple of things to note:
