---
title: "Get started with epipredict"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Get started with epipredict}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
source(here::here("vignettes/_common.R"))
```

```{r setup, message=FALSE, include = FALSE}
library(dplyr)
library(parsnip)
library(workflows)
library(recipes)
library(epidatasets)
library(epipredict)
library(ggplot2)
forecast_date <- as.Date("2021-08-01")
used_locations <- c("ca", "ma", "ny", "tx")
library(epidatr)
```

At a high level, the goal of `{epipredict}` is to make running simple machine
learning / statistical forecasters for epidemiology easy.
To do this, we have extended several [tidymodels](https://www.tidymodels.org/)
packages to handle the case of panel time-series data.
Our hope is that it is easy for users with epi training and some statistics to
fit baseline models while still allowing those with more nuanced statistical
understanding to create complicated specializations using the same framework.
Towards that end, epipredict provides two main classes of tools:

1. A set of basic, easy-to-use "canned" forecasters that work out of the box.
    For the basic forecasters, we currently provide:
    * Flatline forecaster: predicts a median that is the last value
      with increasingly wide quantiles.
    * Autoregressive forecaster: fits a model (e.g. linear regression) on
      lagged data to predict quantiles for continuous values.
    * Autoregressive classifier: fits a model (e.g. logistic regression) on
      lagged data to predict a binned version of the growth rate.
    * CDC FluSight flatline forecaster: a variant of the flatline forecaster as
      used by the CDC in FluSight.
2. A framework for creating custom forecasters out of modular components, from
   which the canned forecasters were created.  There are three types of
   components:
    * Preprocessor: do things to the data before model training, such as convert
      counts to rates, create smoothed columns, or [any of the recipes
      steps](https://recipes.tidymodels.org/reference/index.html)
    * Trainer: train a model on data, resulting in a fitted model object.
      Examples include linear regression, quantile regression, or [any parsnip
      engine](https://parsnip.tidymodels.org/).
    * Postprocessor: unique to this package, and used to do things to the
      predictions after the model has been fit, such as 
      - generate quantiles from purely point-prediction models,
      - undo operations done in the steps, such as convert back to counts from
      rates
      - generally adapt the format of the prediction to it's eventual use.

The rest of the getting started will focus on using and modifying the canned forecasters. 
If you need a more complicated model, check out the [Guts
vignette](preprocessing-and-models) for examples of using the forecaster
framework.

If you are interested in time series in a non-panel data context, you may also
want to look at `{timetk}` and `{modeltime}` for some related techniques.

For a more in-depth treatment with some practical applications, see also the
[Forecasting Book](https://cmu-delphi.github.io/delphi-tooling-book/).

# Panel forecasting basics
## Example data

The forecasting methods in this package are designed to work with panel time
series data, specifically in the form of an `epi_df` from the `{epiprocess}`
package.
This is a collection of one or more time-series indexed by one or more
categorical variables.
For example, on the landing page:

```{r data_ex}
covid_case_death_rates
```

`geo_value` is the only key for this dataset, while there are two separate
time-series, `case_rate` and `death_rate`.
The keys are represented in "long" format (so separate columns for the key and
the value), while separate time series are represented in "wide" format (so each
time-series has a separate column).

`{epiprocess}` is designed to handle data that always has a geographic key, and
potentially other key values, such as age, ethnicity or other demographic
information.
For example, `grad_employ_subset` from `{epidatasets}` also has both `age_group`
and `edu_qual` as additional keys:

```{r extra_keys}
grad_employ_subset
```

See `{epiprocess}` for more details
on the format.

Panel time series are ubiquitous in epidemiology, but are also common in
economics, psychology, sociology, and many other areas.
While this package was designed with epidemiology in mind, many of the
techniques are more broadly applicable.

## Customizing `arx_forecaster()`
Moving on from the example on the [landing
page](../index.html#motivating-example), let's adjust some parameters for
`arx_forecaster()`.
`trainer` allows us to set a different fitting engines, either one of the
included ones, such as `quantile_reg()`, or one of the relevant [parsnip
models](https://www.tidymodels.org/find/parsnip/):

```{r make-forecasts, warning=FALSE}
two_week_ahead <- arx_forecaster(
  covid_case_death_rates |> filter(time_value <= forecast_date),
  outcome = "death_rate",
  trainer = quantile_reg(),
  predictors = c("death_rate"),
  args_list = arx_args_list(
    lags = list(c(0, 7, 14)),
    ahead = 14
  )
)
hardhat::extract_fit_engine(two_week_ahead$epi_workflow)
```

The default trainer is `parsnip::linear_reg()`, which generates quantiles after
the fact in the post-processing layers, rather than as part of the model.
While this does work, it is generally preferable to use `quantile_reg()`, as the
quantiles generated in this manner can be poorly behaved.
`quantile_reg()` on the other hand directly estimates different linear models
for each quantile, reflected in the 3 different columns for `tau` above.

Because of the flexibility of `{parsnip}`, there are a whole host of models
available to us[^5]; as an example, we could have just as easily substituted a
non-linear random forest model from `{ranger}`:

```{r rand_forest_ex, warning=FALSE}
two_week_ahead <- arx_forecaster(
  covid_case_death_rates |> filter(time_value <= forecast_date),
  outcome = "death_rate",
  trainer = rand_forest(mode = "regression"),
  predictors = c("death_rate"),
  args_list = arx_args_list(
    lags = list(c(0, 7, 14)),
    ahead = 14
  )
)
```

Any other customization is routed through `arx_args_list()`; for example, if we
wanted to increase the number of quantiles fit:

```{r make-quantile-levels-forecasts, warning=FALSE}
two_week_ahead <- arx_forecaster(
  covid_case_death_rates |>
    filter(time_value <= forecast_date, geo_value %in% used_locations),
  outcome = "death_rate",
  trainer = quantile_reg(),
  predictors = c("death_rate"),
  args_list = arx_args_list(
    lags = list(c(0, 7, 14)),
    ahead = 14,
    ############ changing quantile_levels ############
    quantile_levels = c(0.05, 0.1, 0.2, 0.3, 0.5, 0.7, 0.8, 0.9, 0.95)
    ##################################################
  )
)
hardhat::extract_fit_engine(two_week_ahead$epi_workflow)
```

See the function documentation of `arx_args_list()` for more examples of the modifications available.
If you are looking for even further modifications, you will want a custom
workflow, for which you should see the [guts
vignette](preprocessing-and-models).

## Generating multiple aheads
Frequently, one doesn't want just a forecast for a single day, but a trajectory
of forecasts for several weeks.
The way to do this using `arx_forecaster()` is by looping over aheads; for
example, to predict every day over 4 weeks:

```{r temp-thing}
all_canned_results <- lapply(
  seq(0, 28),
  \(days_ahead) {
    arx_forecaster(
      covid_case_death_rates |>
        filter(time_value <= forecast_date, geo_value %in% used_locations),
      outcome = "death_rate",
      predictors = c("case_rate", "death_rate"),
      trainer = quantile_reg(),
      args_list = arx_args_list(
        lags = list(c(0, 1, 2, 3, 7, 14), c(0, 7, 14)),
        ahead = days_ahead
      )
    )
  }
)
# pull out the workflow and the predictions to be able to
#  effectively use autoplot
workflow <- all_canned_results[[1]]$epi_workflow
results <- purrr::map_df(all_canned_results, ~ `$`(., "predictions"))
autoplot(
  object = workflow,
  predictions = results,
  plot_data = covid_case_death_rates |>
    filter(geo_value %in% used_locations, time_value > "2021-07-01")
)
```

## Other canned forecasters
### `flatline_forecaster()`
The simplest model we provide is the `flatline_forecaster()`, which predicts a
flat line (with quantiles generated from the residuals using
`layer_residual_quantiles()`).
For example, on the same dataset as above:
```{r make-flatline-forecast, warning=FALSE}
all_flatlines <- lapply(
  seq(0, 28),
  \(days_ahead) {
    flatline_forecaster(
      covid_case_death_rates |>
        filter(time_value <= forecast_date, geo_value %in% used_locations),
      outcome = "death_rate",
      args_list = flatline_args_list(
        ahead = days_ahead,
        quantile_levels = c(0.05, 0.5, 0.95)
      )
    )
  }
)
# same plotting code as in the arx multi-ahead case
workflow <- all_flatlines[[1]]$epi_workflow
results <- purrr::map_df(all_flatlines, ~ `$`(., "predictions"))
results %>% filter(target_date == max(target_date))
autoplot(
  object = workflow,
  predictions = results,
  plot_data = covid_case_death_rates |> filter(geo_value %in% used_locations, time_value > "2021-07-01")
)
```

Note that the `cdc_baseline_forecaster` is a slight modification of this method
for use in [the CDC COVID19 Forecasting Hub](https://covid19forecasthub.org/).

### `arx_classifier()`

The most complicated of the canned forecasters, `arx_classifier` first
translates the outcome into a growth rate, and then classifies that growth rate
into bins.
For example, on the same dataset and `forecast_date` as above, we get:

```{r discrete-rt}
classifier <- arx_classifier(
  covid_case_death_rates |>
    filter(geo_value %in% used_locations, time_value < forecast_date),
  outcome = "death_rate",
  predictors = c("death_rate", "case_rate"),
  trainer = multinom_reg(),
  args_list = arx_class_args_list(
    lags = list(c(0, 1, 2, 3, 7, 14), c(0, 7, 14)),
    ahead = 2 * 7,
    breaks = c(-0.01, 0.01, 0.1)
  )
)
classifier$predictions
```

The prediction splits into 4 cases: `(-∞, -0.01)`, `(-0.01, 0.01)`,  `(0.01,
0.1)`, and `(0.1, ∞)`.
In this case, the classifier put all 4 of the states in the same category,
`(0.01, 0.1)`. **TODO** _effected by the old data._
The number and size of the categories is controlled by `breaks`, which gives the
boundary values.

For comparison, the growth rates for the `target_date`, as computed using
`{epiprocess}`:

```{r growth_rate_results}
growth_rates <- covid_case_death_rates |>
  filter(geo_value %in% used_locations) |>
  group_by(geo_value) |>
  mutate(
    deaths_gr = growth_rate(x = time_value, y = death_rate)
  ) |>
  ungroup()
growth_rates |> filter(time_value == "2021-08-14")
```

Unfortunately, this forecast was not particularly accurate, since for example
`-1.39` is not remotely in the interval `(-0.01, 0.01]`.


## Fitting multi-key panel data

If you have multiple keys that are set in the `epi_df` as `other_keys`,
`arx_forecaster` will automatically group by those as well.
For example, predicting the number of graduates in each of the categories in `grad_employ` from above:

```{r multi_key_forecast, warning=FALSE}
# only fitting a subset, otherwise there are ~550 distinct pairs, which is bad for plotting
edu_quals <- c("Undergraduate degree", "Professional degree")
geo_values <- c("Quebec", "British Columbia")
grad_forecast <- arx_forecaster(
  grad_employ_subset |>
    filter(time_value < 2017) |>
    filter(edu_qual %in% edu_quals, geo_value %in% geo_values),
  outcome = "num_graduates",
  predictors = c("num_graduates"),
  args_list = arx_args_list(
    lags = list(c(0, 1, 2)),
    ahead = 1
  )
)
# and plotting
autoplot(
  grad_forecast$epi_workflow,
  grad_forecast$predictions,
  grad_employ_subset |>
    filter(edu_qual %in% edu_quals, geo_value %in% geo_values),
)
```

The 8 graphs are all pairs of the `geo_values` (`"Quebec"` and `"British Columbia"`), `edu_quals` (`"Undergraduate degree"` and `"Professional degree"`), and age brackets (`"15 to 34 years"` and `"35 to 64 years"`).

# Anatomy of a canned forecaster
## Code object
Let's dissect the forecaster we trained back on the [landing
page](../index.html#motivating-example):

```{r make-four-forecasts, warning=FALSE}
four_week_ahead <- arx_forecaster(
  covid_case_death_rates |> filter(time_value <= forecast_date),
  outcome = "death_rate",
  predictors = c("case_rate", "death_rate"),
  args_list = arx_args_list(
    lags = list(c(0, 1, 2, 3, 7, 14), c(0, 7, 14)),
    ahead = 4 * 7,
    quantile_levels = c(0.1, 0.25, 0.5, 0.75, 0.9)
  )
)
```

`four_week_ahead` has two components: an `epi_workflow`, and a table of
`predictions`.
The table of predictions is simply a tibble of the predictions,

```{r show_predictions}
four_week_ahead$predictions
```

`.pred` gives the point/median prediction, while `.pred_distn` is a
`dist_quantiles()` object representing a distribution through various quantile
levels.
The `[6]` in the name refers to the number of quantiles that have been
explicitly created[^4]; by default, this covers a 90% prediction interval, or 5%
and 95%.

The `epi_workflow` is a significantly more complicated object, extending a
`workflows::workflow()`  to include post-processing:

```{r show_workflow}
four_week_ahead$epi_workflow
```

An `epi_workflow()` consists of 3 parts:

- `Preprocessor`: a collection of steps that transform the data to be ready for
      modelling. They come from this package or [any of the recipes
      steps](https://recipes.tidymodels.org/reference/index.html);
      `four_week_ahead` has 5 of these, and you can inspect them more closely by
      running `hardhat::extract_recipe(four_week_ahead$epi_workflow)`.[^6]
- `Model`: the actual model that does the fitting, given by a
  `parsnip::model_spec`; `four_week_ahead` has the default of
  `parsnip::linear_reg()`, which is a wrapper from `{parsnip}` for
  `stats::lm()`. You can inspect the model more closely by running
  `hardhat::extract_fit_recipe(four_week_ahead$epi_workflow)`.
- `Postprocessor`: a collection of layers to be applied to the resulting
  forecast, internal to this package. `four_week_ahead` just so happens to have
  5 of as these well. You can inspect the layers more closely by running
  `epipredict::extract_layers(four_week_ahead$epi_workflow)`.

See the [Guts vignette](preprocessing-and-models) for recreating and then
extending `four_week_ahead` using the custom forecaster framework.

## Mathematical description

Let's describe in more detail the actual fit model for a more minimal version of
`four_week_ahead`:

```{r, four_week_again}
four_week_small <- arx_forecaster(
  covid_case_death_rates |> filter(time_value <= forecast_date),
  outcome = "death_rate",
  predictors = c("case_rate", "death_rate"),
  args_list = arx_args_list(
    lags = list(c(0, 7, 14), c(0, 7, 14)),
    ahead = 4 * 7,
    quantile_levels = c(0.1, 0.25, 0.5, 0.75, 0.9)
  )
)
hardhat::extract_fit_engine(four_week_small$epi_workflow)
```

If $d_t$ is the death rate on day $t$ and $c_t$ is the case rate, then the model
we're fitting is:

$$
d_{t+28} = a_0 + a_1 d_t + a_2 d_{t-7} + a_3 d_{t-14} + a_4 c_t + a_5 c_{t-7} + a_6 c_{t-14}.
$$

For example, $a_1$ is `lag_0_death_rate` above, with a value of `r hardhat::extract_fit_engine(four_week_small$epi_workflow)$coefficients["lag_0_death_rate"] `,
while $a_5$ is `r hardhat::extract_fit_engine(four_week_small$epi_workflow)$coefficients["lag_7_case_rate"] `.

The training data for fitting this linear model is created by creating a series
of columns shifted by the appropriate amount; this makes it so that each row
without `NA` values is a training point to fit the coefficients $a_0,\ldots, a_6$.

[^4]: in the case of a `{parsnip}` engine which doesn't explicitly predict
    quantiles, these quantiles are created using `layer_residual_quantiles()`,
    which infers the quantiles from the residuals of the fit.

[^5]: in the case of `arx_forecaster`, this is any model with
    `mode="regression"` from [this
    list](https://www.tidymodels.org/find/parsnip/).

[^6]: alternatively, for an unfit version of the preprocessor, you can call
    `hardhat::extract_preprocessor(four_week_ahead$epi_workflow)`
